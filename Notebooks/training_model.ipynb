{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Training_Model notebook\n",
    "\n",
    "Goals of this notebook:\n",
    "* Train a Model to classify suspicious firms as such, given their data\n",
    "\n",
    "###### The Auditor Office of India, officially known as the Comptroller and Auditor General of India (CAG), is a Central Government Agency established by the Indian Constitution with the express purpose of ensuring public funds are being used properly (making sure the gov't isn't being scammed). It does this by auditing Central and State Government accounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "The dataset is the 'Audit Data' dataset from the UCI Machine Learning Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = pd.read_csv('../audit_data/audit_risk.csv') # 'ad' for 'audit data'\n",
    "td = pd.read_csv('../audit_data/trial.csv') # 'td' for 'trial data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sector_score', 'LOCATION_ID', 'PARA_A', 'Score_A', 'Risk_A', 'PARA_B',\n",
      "       'Score_B', 'Risk_B', 'TOTAL', 'numbers', 'Score_B.1', 'Risk_C',\n",
      "       'Money_Value', 'Score_MV', 'Risk_D', 'District_Loss', 'PROB', 'RiSk_E',\n",
      "       'History', 'Prob', 'Risk_F', 'Score', 'Inherent_Risk', 'CONTROL_RISK',\n",
      "       'Detection_Risk', 'Audit_Risk', 'Risk'],\n",
      "      dtype='object')\n",
      "Index(['Sector_score', 'LOCATION_ID', 'PARA_A', 'SCORE_A', 'PARA_B', 'SCORE_B',\n",
      "       'TOTAL', 'numbers', 'Marks', 'Money_Value', 'MONEY_Marks', 'District',\n",
      "       'Loss', 'LOSS_SCORE', 'History', 'History_score', 'Score', 'Risk'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>Score_A</th>\n",
       "      <th>Risk_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>Score_B</th>\n",
       "      <th>Risk_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>...</th>\n",
       "      <th>RiSk_E</th>\n",
       "      <th>History</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Risk_F</th>\n",
       "      <th>Score</th>\n",
       "      <th>Inherent_Risk</th>\n",
       "      <th>CONTROL_RISK</th>\n",
       "      <th>Detection_Risk</th>\n",
       "      <th>Audit_Risk</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>3.41</td>\n",
       "      <td>11</td>\n",
       "      <td>6.31</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.786</td>\n",
       "      <td>19.42</td>\n",
       "      <td>0.6</td>\n",
       "      <td>11.652</td>\n",
       "      <td>25.73</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>26.366</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.2732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2.72</td>\n",
       "      <td>1</td>\n",
       "      <td>4.36</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.616</td>\n",
       "      <td>33.91</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20.346</td>\n",
       "      <td>38.27</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>29.986</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>35.9832</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.89</td>\n",
       "      <td>14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.206</td>\n",
       "      <td>1.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.606</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2.37</td>\n",
       "      <td>2</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.058</td>\n",
       "      <td>1.19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.682</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>3.41</td>\n",
       "      <td>32</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.200</td>\n",
       "      <td>49.19</td>\n",
       "      <td>0.6</td>\n",
       "      <td>29.514</td>\n",
       "      <td>51.19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>69.042</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>27.6168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>2.34</td>\n",
       "      <td>2</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.370</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>56.546</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>45.2368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2.72</td>\n",
       "      <td>11</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.106</td>\n",
       "      <td>52.89</td>\n",
       "      <td>0.6</td>\n",
       "      <td>31.734</td>\n",
       "      <td>56.40</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>36.092</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.2184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1.99</td>\n",
       "      <td>8</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.71</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.102</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3.89</td>\n",
       "      <td>19</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.940</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2.37</td>\n",
       "      <td>13</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.554</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.132</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.342</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sector_score LOCATION_ID  PARA_A  Score_A  Risk_A  PARA_B  Score_B  \\\n",
       "161          3.41          11    6.31      0.6   3.786   19.42      0.6   \n",
       "242          2.72           1    4.36      0.6   2.616   33.91      0.6   \n",
       "28           3.89          14    0.00      0.2   0.000    1.03      0.2   \n",
       "340          2.37           2    0.90      0.2   0.180    0.29      0.2   \n",
       "169          3.41          32    2.00      0.6   1.200   49.19      0.6   \n",
       "489          2.34           2    3.95      0.6   2.370    0.00      0.2   \n",
       "213          2.72          11    3.51      0.6   2.106   52.89      0.6   \n",
       "350          1.99           8    1.71      0.4   0.684    0.00      0.2   \n",
       "44           3.89          19    1.32      0.4   0.528    0.00      0.2   \n",
       "280          2.37          13    2.59      0.6   1.554    0.66      0.2   \n",
       "\n",
       "     Risk_B  TOTAL  numbers  ...  RiSk_E  History  Prob  Risk_F  Score  \\\n",
       "161  11.652  25.73      5.5  ...     0.4        0   0.2     0.0    4.4   \n",
       "242  20.346  38.27      5.5  ...     2.4        0   0.2     0.0    4.8   \n",
       "28    0.206   1.03      5.0  ...     0.4        0   0.2     0.0    2.0   \n",
       "340   0.058   1.19      5.0  ...     1.2        0   0.2     0.0    2.4   \n",
       "169  29.514  51.19      5.0  ...     0.4        1   0.4     0.4    4.2   \n",
       "489   0.000   0.00      5.5  ...     1.2        1   0.4     0.4    3.8   \n",
       "213  31.734  56.40      5.0  ...     0.4        0   0.2     0.0    3.6   \n",
       "350   0.000   1.71      5.0  ...     0.4        0   0.2     0.0    2.2   \n",
       "44    0.000   1.32      5.0  ...     0.4        0   0.2     0.0    2.2   \n",
       "280   0.132   3.25      5.0  ...     0.4        0   0.2     0.0    2.4   \n",
       "\n",
       "     Inherent_Risk  CONTROL_RISK  Detection_Risk  Audit_Risk  Risk  \n",
       "161         26.366           0.4             0.5      5.2732     1  \n",
       "242         29.986           2.4             0.5     35.9832     1  \n",
       "28           1.606           0.4             0.5      0.3212     0  \n",
       "340          2.682           1.2             0.5      1.6092     1  \n",
       "169         69.042           0.8             0.5     27.6168     1  \n",
       "489         56.546           1.6             0.5     45.2368     1  \n",
       "213         36.092           0.4             0.5      7.2184     1  \n",
       "350          2.102           0.4             0.5      0.4204     0  \n",
       "44           1.940           0.4             0.5      0.3880     0  \n",
       "280          3.342           0.4             0.5      0.6684     0  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic Visualization\n",
    "\n",
    "print(ad.columns) # to see the different columns that ad and td have\n",
    "print(td.columns)\n",
    "\n",
    "ad.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare 'ad' and 'td' for PCA\n",
    "\n",
    "Removing incompatible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating 'ad' for NaN values and readying it for pca:\n",
      "\n",
      "Shape of the original ad is (776, 27)\n",
      "Shape after removing the 3 rows with Loharu Nuh and Safidon is (773, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>Score_A</th>\n",
       "      <th>Risk_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>Score_B</th>\n",
       "      <th>Risk_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Score_B.1</th>\n",
       "      <th>Risk_C</th>\n",
       "      <th>Money_Value</th>\n",
       "      <th>Score_MV</th>\n",
       "      <th>Risk_D</th>\n",
       "      <th>District_Loss</th>\n",
       "      <th>PROB</th>\n",
       "      <th>RiSk_E</th>\n",
       "      <th>History</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Risk_F</th>\n",
       "      <th>Score</th>\n",
       "      <th>Inherent_Risk</th>\n",
       "      <th>CONTROL_RISK</th>\n",
       "      <th>Detection_Risk</th>\n",
       "      <th>Audit_Risk</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>55.57</td>\n",
       "      <td>4</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.446</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sector_score LOCATION_ID  PARA_A  Score_A  Risk_A  PARA_B  Score_B  \\\n",
       "642         55.57           4    0.23      0.2   0.046     0.0      0.2   \n",
       "\n",
       "     Risk_B  TOTAL  numbers  Score_B.1  Risk_C  Money_Value  Score_MV  Risk_D  \\\n",
       "642     0.0   0.23      5.0        0.2     1.0          NaN       0.2     0.0   \n",
       "\n",
       "     District_Loss  PROB  RiSk_E  History  Prob  Risk_F  Score  Inherent_Risk  \\\n",
       "642              2   0.2     0.4        0   0.2     0.0    2.0          1.446   \n",
       "\n",
       "     CONTROL_RISK  Detection_Risk  Audit_Risk  Risk  \n",
       "642           0.4             0.5      0.2892     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping na is (772, 27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# PCA SECTION - USING PCA TO FIND HOW IMPORTANT EACH COLUMN IS\\nprint('Pca section - using pca to find the relative importance(explained variance) of each column:\\n')\\n\\n# PCA and Pandas are already imported\\n\\npca = PCA()\\n\\npca.fit(ad_stringless)\\nad_explained_variance_ratio = pca.explained_variance_ratio_ # must be ratio, otherwise it's just absolute values that don't really mean much to us\\n\\nprint('Audit Data (ad) columns and explained variance:\\n')\\nprint(ad.columns + '\\n')\\nnp.set_printoptions(precision=4, suppress=True) \\nprint(ad_explained_variance_ratio)\\n\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Attempting PCA on ad to prepare it for logistic regression\n",
    "\n",
    "from IPython.display import display #display module for jupyter notebook, allowing me to manually force Jupyter to display in the nice UI form\n",
    "\n",
    "#INVESTGATING 'ad' FOR NaN values / READYING IT FOR PCA\n",
    "print('Investigating \\'ad\\' for NaN values and readying it for pca:\\n')\n",
    "\n",
    "ad.loc[ad.LOCATION_ID.isin(['LOHARU', 'NUH', 'SAFIDON'])] #find the row index numbers where these strings are in LOCATION_ID\n",
    "\n",
    "#print(ad.head(10))\n",
    "ad_stringless = ad.copy().drop([351,355,367], axis=0)\n",
    "print(f'Shape of the original ad is {ad.shape}')\n",
    "print(f'Shape after removing the 3 rows with Loharu Nuh and Safidon is {ad_stringless.shape}')\n",
    "pd.set_option('display.max_columns', None)\n",
    "#print(ad_stringless.isna().any(axis=0)) # checks if there's an NA in any column, and if so, labels that column as \"True\"\n",
    "display(ad_stringless[ad_stringless.isna().any(axis=1)]) # returns the rows with at least 1 box that is NA, in the nice UI form\n",
    "\n",
    "pd.reset_option('display.max_columns')\n",
    "\n",
    "ad_stringless = ad_stringless.dropna()\n",
    "print(f'Shape after dropping na is {ad_stringless.shape}')\n",
    "\n",
    "'''\n",
    "# PCA SECTION - USING PCA TO FIND HOW IMPORTANT EACH COLUMN IS\n",
    "print('Pca section - using pca to find the relative importance(explained variance) of each column:\\n')\n",
    "\n",
    "# PCA and Pandas are already imported\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "pca.fit(ad_stringless)\n",
    "ad_explained_variance_ratio = pca.explained_variance_ratio_ # must be ratio, otherwise it's just absolute values that don't really mean much to us\n",
    "\n",
    "print('Audit Data (ad) columns and explained variance:\\n')\n",
    "print(ad.columns + '\\n')\n",
    "np.set_printoptions(precision=4, suppress=True) \n",
    "print(ad_explained_variance_ratio)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating 'td' for NaN values and readying it for pca:\n",
      "\n",
      "Shape of the original td is (776, 18)\n",
      "Shape after removing the 3 rows with Loharu Nuh and Safidon is (773, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>SCORE_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>SCORE_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Marks</th>\n",
       "      <th>Money_Value</th>\n",
       "      <th>MONEY_Marks</th>\n",
       "      <th>District</th>\n",
       "      <th>Loss</th>\n",
       "      <th>LOSS_SCORE</th>\n",
       "      <th>History</th>\n",
       "      <th>History_score</th>\n",
       "      <th>Score</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>55.57</td>\n",
       "      <td>4</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sector_score LOCATION_ID  PARA_A  SCORE_A  PARA_B  SCORE_B  TOTAL  \\\n",
       "642         55.57           4    0.23        2     0.0        2   0.23   \n",
       "\n",
       "     numbers  Marks  Money_Value  MONEY_Marks  District  Loss  LOSS_SCORE  \\\n",
       "642      5.0      2          NaN            2         2     0           2   \n",
       "\n",
       "     History  History_score  Score  Risk  \n",
       "642        0              2    2.0     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping na is (772, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# PCA SECTION - USING PCA TO FIND HOW IMPORTANT EACH COLUMN IS\\nprint('Pca section - using pca to find the relative importance(explained variance) of each column:\\n')\\n\\n# PCA and Pandas are already imported\\n\\npca = PCA()\\n\\npca.fit(td_stringless)\\ntd_explained_variance_ratio = pca.explained_variance_ratio_ # must be ratio, otherwise it's just absolute values that don't really mean much to us\\n\\nprint('Trial Data (td) columns and explained variance:\\n')\\nprint(td.columns + '\\n')\\nnp.set_printoptions(precision=4, suppress=True) \\nprint(td_explained_variance_ratio)\\n\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Attempting PCA on td to prepare it for logistic regression\n",
    "\n",
    "from IPython.display import display #display module for jupyter notebook, allowing me to manually force Jupyter to display in the nice UI form\n",
    "\n",
    "#INVESTGATING 'td' FOR NaN values / READYING IT FOR PCA\n",
    "print('Investigating \\'td\\' for NaN values and readying it for pca:\\n')\n",
    "\n",
    "td.loc[td.LOCATION_ID.isin(['LOHARU', 'NUH', 'SAFIDON'])] #find the row index numbers where these strings are in LOCATION_ID\n",
    "\n",
    "#print(td.head(10))\n",
    "td_stringless = td.copy().drop([351,355,367], axis=0)\n",
    "print(f'Shape of the original td is {td.shape}')\n",
    "print(f'Shape after removing the 3 rows with Loharu Nuh and Safidon is {td_stringless.shape}')\n",
    "pd.set_option('display.max_columns', None)\n",
    "#print(td_stringless.isna().any(axis=0)) # checks if there's an NA in any column, and if so, labels that column as \"True\"\n",
    "display(td_stringless[td_stringless.isna().any(axis=1)]) # returns the rows with at least 1 box that is NA, in the nice UI form\n",
    "\n",
    "pd.reset_option('display.max_columns')\n",
    "\n",
    "td_stringless = td_stringless.dropna()\n",
    "print(f'Shape after dropping na is {td_stringless.shape}')\n",
    "\n",
    "'''\n",
    "# PCA SECTION - USING PCA TO FIND HOW IMPORTANT EACH COLUMN IS\n",
    "print('Pca section - using pca to find the relative importance(explained variance) of each column:\\n')\n",
    "\n",
    "# PCA and Pandas are already imported\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "pca.fit(td_stringless)\n",
    "td_explained_variance_ratio = pca.explained_variance_ratio_ # must be ratio, otherwise it's just absolute values that don't really mean much to us\n",
    "\n",
    "print('Trial Data (td) columns and explained variance:\\n')\n",
    "print(td.columns + '\\n')\n",
    "np.set_printoptions(precision=4, suppress=True) \n",
    "print(td_explained_variance_ratio)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes about PCA preparation above, done to ad and td\n",
    "\n",
    "1. In both 'ad' and 'td', there are 3 rows where the LOCATION_ID is string, so it is not a float, and hence not compatible with pca. Hence, they were removed.\n",
    "2. In 'ad', for some reason, in row 642, 'Money_Value' is NaN. So, I removed the row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train logistic regression models\n",
    "\n",
    "On ad and td both, separately (the columns in td are not a proper subset of ad's columns, so both must be modeled separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-PCA Metrics\n",
      "Classification accuracy: 0.9844559585492227\n",
      "F1 Score: 0.9795918367346939\n",
      "\n",
      "Post-PCA Metrics\n",
      "Number of dimensions before PCA: 26\n",
      "Number of dimensions after PCA: 9\n",
      "Classification accuracy after PCA: 0.9896373056994818\n",
      "F1 Score after PCA: 0.9864864864864865\n"
     ]
    }
   ],
   "source": [
    "# Training a logistic regression model on ad (with and without PCA)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Create input and output + train_test_split\n",
    "ad_input_data = ad_stringless.drop('Risk', axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(ad_input_data, ad_stringless.Risk, random_state=0)\n",
    "\n",
    "# Standardize Data (for efficient logistic regression)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression without PCA\n",
    "lg_ad = LogisticRegression()\n",
    "lg_ad.fit(X_train, Y_train)\n",
    "\n",
    "print('Pre-PCA Metrics')\n",
    "# Accuracy\n",
    "print('Classification accuracy: ' + str(lg_ad.score(X_test, Y_test)))\n",
    "#F1 score\n",
    "Y_pred = lg_ad.predict(X_test)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "print('F1 Score:', f1)\n",
    "\n",
    "\n",
    "# Logistic Regression with PCA\n",
    "pca = PCA(n_components = 0.9, random_state = 0)\n",
    "pca.fit(X_train)\n",
    "X_train_PCA = pca.transform(X_train)\n",
    "X_test_PCA = pca.transform(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "pca_lg_ad = LogisticRegression()\n",
    "pca_lg_ad.fit(X_train_PCA, Y_train)\n",
    "\n",
    "print('\\nPost-PCA Metrics')\n",
    "print('Number of dimensions before PCA: ' + str(len(ad_input_data.columns)))\n",
    "print('Number of dimensions after PCA: ' + str(pca.n_components_))\n",
    "print('Classification accuracy after PCA: ' + str(pca_lg_ad.score(X_test_PCA, Y_test)))\n",
    "#F1 score\n",
    "Y_pred = pca_lg_ad.predict(X_test_PCA)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "print('F1 Score after PCA:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-PCA Metrics\n",
      "Classification accuracy: 0.9896373056994818\n",
      "F1 Score: 0.9915966386554622\n",
      "\n",
      "Post-PCA Metrics\n",
      "Number of dimensions before PCA: 17\n",
      "Number of dimensions after PCA: 9\n",
      "Classification accuracy after PCA: 0.9844559585492227\n",
      "F1 Score after PCA: 0.9873417721518988\n"
     ]
    }
   ],
   "source": [
    "# Training a logistic regression model on td (with and without PCA)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline # to make it easier\n",
    "\n",
    "# Create input and output + train_test_split\n",
    "td_input_data = td_stringless.drop('Risk', axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(td_input_data, td_stringless.Risk, random_state=0)\n",
    "\n",
    "# Pipeline without PCA\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('logistic', LogisticRegression())])\n",
    "\n",
    "pipe.fit(X_train, Y_train)\n",
    "\n",
    "#Metrics\n",
    "print('Pre-PCA Metrics')\n",
    "print('Classification accuracy: ' + str(pipe.score(X_test, Y_test))) # Accuracy\n",
    "Y_pred = pipe.predict(X_test) #F1 score calc\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "print('F1 Score:', f1) #F1 score\n",
    "\n",
    "\n",
    "# Pipeline with PCA\n",
    "pca_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('pca', PCA(n_components=0.9, random_state=0)),\n",
    "                 ('logistic', LogisticRegression())])\n",
    "\n",
    "pca_pipe.fit(X_train, Y_train)\n",
    "\n",
    "#Metrics\n",
    "print('\\nPost-PCA Metrics')\n",
    "print('Number of dimensions before PCA: ' + str(len(td_input_data.columns)))\n",
    "print('Number of dimensions after PCA: ' + str(pca_pipe.named_steps['pca'].n_components_))\n",
    "print('Classification accuracy after PCA: ' + str(pca_pipe.score(X_test, Y_test)))  # Accuracy\n",
    "Y_pred = pca_pipe.predict(X_test) #F1 score calc\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "print('F1 Score after PCA:', f1) #F1 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results\n",
    "\n",
    "Results of Logistic Regression Model Training:\n",
    "1. PCA reduces features to 9 components in both\n",
    "2. For 'ad', PCA improves F1 score and classification accuracy\n",
    "3. For 'td', PCA does not improve F1 score and classification accuracy\n",
    "4. The effect of a 90% PCA seems to be marginal, either way (accuracy going up or down)\n",
    "\n",
    "Steps were:\n",
    "1. Get the data PCA-ready (done in the previous step)\n",
    "2. Standardize the data\n",
    "3. PCA(or not) the data with 90% variance retained\n",
    "4. Train a logistic regression model\n",
    "5. Metrics\n",
    "* Accuracy and F1 score\n",
    "* How many dimension PCA removed, if PCA was done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
